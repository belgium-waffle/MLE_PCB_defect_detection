
# ğŸ” PCB Defect Detection using YOLOv8  
### BITS Pilani â€” Machine Learning for EEE (MLE) Course Project  
**Team Members:**  
- Jaikumar Wath (2023A3PS0197G)  
- Aditya Mane (2023A3PS0505G)  
- Vaibhav Divakar (2023A3PS0527G)

---

## ğŸ“Œ Project Overview

This repository contains our full pipeline for **automated PCB defect detection** using **YOLOv8**.  
The goal is to reliably detect six types of microscopic PCB manufacturing defects:

- Missing hole  
- Mouse bite  
- Open circuit  
- Short  
- Spur  
- Spurious copper  

The project includes:

- ğŸ“ Complete dataset preprocessing pipeline  
- ğŸ”„ XML â†’ YOLO format annotation conversion  
- ğŸ§  Training using YOLOv8m (768Ã—768)  
- ğŸ”ƒ 3-Fold Cross Validation  
- ğŸ“Š Training curves + detailed metrics  
- ğŸŒ Deployment as a **Gradio Web Application**  
- ğŸ“¦ Released final trained model  

---

## ğŸ“ **Repository Structure**

- **Website/**
  - Gradio Web App (final deployed product)

- **example_images/**
  - Sample accurate model output images for you to see 

- **final_results/**
  - Final validation metrics, loss curves, training plots, and prediction screenshots

- **midsem/**
  - Mid-semester submission (baseline code, report, and intermediate results)

- **git_vs_us/**
  - Comparison between public GitHub YOLOv8 training scripts and our optimized pipeline
  - Includes YOLOv8m vs YOLOv8s comparison experiments

- **finalyolov8m.ipynb**
  - Main training notebook (YOLOv8m at 768Ã—768 with 3-Fold Cross-Validation)

- **README.md**
  - Full project documentation (this file)

- **Release/Final_Trained_Model/**
  - Exported final model weights (`best.pt`, `best.torchscript`)


---

## ğŸ“¦ Dataset Information

We use the **PCB Defects** dataset released by the  
*Open Lab on Humanâ€“Robot Interaction (Peking University)*.

Dataset link:  
ğŸ”— **https://www.kaggle.com/datasets/akhatova/pcb-defects/data**

Dataset structure (per class):



PCB_DATASET/
â”œâ”€â”€ images/
â”‚ â”œâ”€â”€ Missing_hole/
â”‚ â”œâ”€â”€ Mouse_bite/
â”‚ â”œâ”€â”€ Open_circuit/
â”‚ â”œâ”€â”€ Short/
â”‚ â”œâ”€â”€ Spur/
â”‚ â””â”€â”€ Spurious_copper/
â””â”€â”€ Annotations/ (Pascal VOC XML)


We parse all VOC XML annotations and convert them into normalized YOLOv8 `.txt` format.

---

## ğŸ”§ **Key Features of This Project**

### âœ” 1. **Custom XML â†’ YOLO Converter**
We implemented a scalable XML parsing pipeline using `xml.etree.ElementTree`, converting:



xmin, ymin, xmax, ymax â†’ (class, x_center, y_center, width, height)


Fully automatic, supports thousands of images.

---

### âœ” 2. **Correct Letterbox Preprocessing (No Distortion)**  
Unlike naive resizing, our preprocessing:

- preserves aspect ratio  
- pads remaining space with 114  
- applies the same affine transform to bounding boxes  

This matches Ultralytics behavior and improves mAP noticeably.

---

### âœ” 3. **Train/Val/Test Split + K-Fold Cross Validation**

We generate:



train/
val/
test/


and additionally perform **3-fold CV** to evaluate model robustness.

Each fold gets its own:

- images/
- labels/
- dataset.yaml  

---

### âœ” 4. **YOLOv8m Training with Advanced Augmentations**

We train **YOLOv8m (25M params)** at **768Ã—768** resolution using Kaggle GPU (T4/P100).  
Augmentations include:

- Mosaic = 0.8  
- RandAugment  
- Copy-Paste  
- HSV jitter  
- Perspective = 0.0005  
- Erasing = 0.35  

These improve tiny-defect detection significantly.

---

### âœ” 5. **Final Performance (Fold-2 Best Model)**

| Metric        | Score |
|---------------|-------|
| Precision     | **0.966** |
| Recall        | **0.962** |
| mAP@50        | **0.972** |
| mAP@50â€“95     | **0.529** |

Per-class AP values show strong performance across all 6 defect types.

---

### âœ” 6. **Gradio Web Application (Productization)**

We convert our model into a **real, usable tool**:

ğŸ”— *`Website/app.py`* contains a Gradio interface:

- upload a PCB image  
- YOLOv8 runs inference  
- annotated image is returned instantly  

This demonstrates practical deployability for factory QC lines.

---

## ğŸš€ **How to Run the Project**

### 1. Install dependencies

```pip install ultralytics gradio opencv-python-headless matplotlib pandas```

2. Download dataset

Upload the dataset in the same structure as described above.

3. Run the preprocessing + training notebook
jupyter notebook finalyolov8m.ipynb

4. Run the final trained model
from ultralytics import YOLO
model = YOLO("final_model/best.pt")
model.predict("example_images/short_01.jpg")

5. Launch the Gradio Web App
cd Website
python app.py


The interface will be available at:

http://localhost:7860

---

## ğŸ“¥ Download Final Model

The final trained model is provided as part of the GitHub release bundle:

**Included:**
- âœ” `best.pt` (PyTorch YOLOv8 format)

You can download it from:

ğŸ‘‰ **Releases â†’ Final Trained Model**

---

## ğŸ§ª Training Curve Examples

Training logs, epoch-wise metrics, and loss curves are available in:

final_results/


This folder includes:
- Box loss vs. epochs  
- Class loss vs. epochs  
- Distribution focal loss  
- Validation mAP curves  
- Sample predictions  

---

## ğŸ“š Technologies Used

This project was built using:

- **Python 3.10**
- **YOLOv8 (Ultralytics)**
- **PyTorch**
- **OpenCV**
- **NumPy / Pandas**
- **Matplotlib**
- **Gradio (Web Deployment)**
- **Kaggle GPU Compute (T4 / P100)**

---

## ğŸ‘¨â€ğŸ’» Contributions

All team members contributed equally across the following components:

- Dataset preprocessing & organization  
- XML parsing and YOLO label generation  
- Model training and hyperparameter tuning  
- K-Fold cross-validation setup  
- Inference visualization & evaluation  
- Gradio web interface development  
- Report writing and documentation  

---

## ğŸ“„ License

This project is released under the **MIT License**.  
You are free to use, modify, and distribute this project with proper attribution.

---

## â­ Support

If you found this project useful, please consider giving the repository a **â­ star** on GitHub.  
It helps others discover the project and supports our work.

---
