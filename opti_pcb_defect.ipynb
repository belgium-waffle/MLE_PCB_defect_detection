{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SrUaydq-uQOb",
    "outputId": "a843814a-6001-4f33-dd56-c831c5ddd107"
   },
   "outputs": [],
   "source": [
    "\n",
    "root_dir = '/home/arm/Downloads/PCB/'  #make a folder that will contain your PCB_Dataset from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOovCs5iqe56"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "08hK9kjPrSyP"
   },
   "source": [
    "# Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EPtQ1vRDrQff",
    "outputId": "b1ed1ffe-ba68-4b51-95f3-c534e26a7995"
   },
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join(root_dir, 'PCB_DATASET')\n",
    "\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "   for name in dirs:\n",
    "      print(os.path.join(root, name)) #verify all the files from Kaggle dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZG4j3UFnWpjH"
   },
   "outputs": [],
   "source": [
    "def count_files_in_folder(folder_path):\n",
    "    # Get list of all files in the folder\n",
    "    files = os.listdir(folder_path)\n",
    "\n",
    "    # Count the number of files\n",
    "    num_files = len(files)\n",
    "\n",
    "    return num_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_YcUxaUVVCn",
    "outputId": "d5dec9e4-56af-435d-e395-7769ed98cae1"
   },
   "outputs": [],
   "source": [
    "subfolders = ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']\n",
    "\n",
    "images_dir = os.path.join(dataset_dir, 'images')\n",
    "annot_dir = os.path.join(dataset_dir, 'Annotations')\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    images_path = os.path.join(images_dir, subfolder)\n",
    "    annot_path = os.path.join(annot_dir, subfolder)\n",
    "\n",
    "    print(f'{subfolder:<15} \\t\\\n",
    "            {count_files_in_folder(images_path)} images \\t\\\n",
    "            {count_files_in_folder(annot_path)} annotations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u_srlgxrhQ2_"
   },
   "source": [
    "# Create annotaton dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IqYGOYZKkiZp"
   },
   "outputs": [],
   "source": [
    "def parse_xml(xml_file):\n",
    "    # Parse the given XML annotation file (e.g., from Pascal VOC format)\n",
    "    tree = ET.parse(xml_file)       # Load and parse the XML file\n",
    "    root = tree.getroot()           # Get the root element of the XML tree\n",
    "    data = []                       # List to store extracted annotation data\n",
    "\n",
    "    # Extract basic image information\n",
    "    filename = root.find('filename').text       # Image file name\n",
    "    width = int(root.find('size/width').text)   # Image width\n",
    "    height = int(root.find('size/height').text) # Image height\n",
    "\n",
    "    # Loop through each object (defect/label) in the XML file\n",
    "    for obj in root.findall('object'):\n",
    "        name = obj.find('name').text                            # Object class name\n",
    "        xmin = int(obj.find('bndbox/xmin').text)                # Bounding box left (x)\n",
    "        ymin = int(obj.find('bndbox/ymin').text)                # Bounding box top (y)\n",
    "        xmax = int(obj.find('bndbox/xmax').text)                # Bounding box right (x)\n",
    "        ymax = int(obj.find('bndbox/ymax').text)                # Bounding box bottom (y)\n",
    "\n",
    "        # Store all details for this object in a dictionary\n",
    "        data.append({\n",
    "            'filename': filename,\n",
    "            'width': width,\n",
    "            'height': height,\n",
    "            'class': name,\n",
    "            'xmin': xmin,\n",
    "            'ymin': ymin,\n",
    "            'xmax': xmax,\n",
    "            'ymax': ymax\n",
    "        })\n",
    "\n",
    "    return data  # Return the list of all extracted objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pP9lRfh6kmlP"
   },
   "outputs": [],
   "source": [
    "# List to store parsed data from all XML files\n",
    "all_data = []\n",
    "\n",
    "# Recursively traverse subdirectories\n",
    "for root, dirs, files in os.walk(annot_dir):\n",
    "    for name in files:\n",
    "        if name.endswith('.xml'):\n",
    "            xml_path = os.path.join(root, name)\n",
    "            all_data.extend(parse_xml(xml_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zBb3srZZlfld",
    "outputId": "42bd5de0-7ce7-4a6d-b69d-7e93f381031c"
   },
   "outputs": [],
   "source": [
    "# Create DataFrame from the parsed data\n",
    "annot_df = pd.DataFrame(all_data)\n",
    "annot_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PxrWDtWShUVx"
   },
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VEWjyB9Q1t0R"
   },
   "outputs": [],
   "source": [
    "def get_subfolder(image_name):\n",
    "    if 'missing' in image_name.split('_'):\n",
    "        return 'Missing_hole'\n",
    "    if 'mouse' in image_name.split('_'):\n",
    "        return'Mouse_bite'\n",
    "    if 'open' in image_name.split('_'):\n",
    "        return 'Open_circuit'\n",
    "    if 'short' in image_name.split('_'):\n",
    "        return 'Short'\n",
    "    if 'spur' in image_name.split('_'):\n",
    "        return 'Spur'\n",
    "    if 'spurious' in image_name.split('_'):\n",
    "        return 'Spurious_copper'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PwO9BLFs9XNv"
   },
   "outputs": [],
   "source": [
    "def visualize_annotations(image_name, images_dir, annot_df, is_subfolder=False):\n",
    "    # Construct path for image\n",
    "    if is_subfolder:\n",
    "        image_path = os.path.join(images_dir, get_subfolder(image_name), image_name)\n",
    "    else:\n",
    "        image_path = os.path.join(images_dir, image_name)\n",
    "\n",
    "\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Filter annotations for the current image\n",
    "    annotations = annot_df[annot_df['filename'] == image_name]\n",
    "\n",
    "    # Draw bounding boxes on the image\n",
    "    for _, annot in annotations.iterrows():\n",
    "        xmin, ymin, xmax, ymax = annot['xmin'], annot['ymin'], annot['xmax'], annot['ymax']\n",
    "        class_label = annot['class']\n",
    "\n",
    "        # Check if confidence column exists\n",
    "        confidence = annot.get('confidence')\n",
    "        if confidence is not None:\n",
    "            class_label += f\" ({confidence:.2f})\"\n",
    "\n",
    "        color = (255, 255, 255)\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), color, 3)\n",
    "\n",
    "        # Add background to the text\n",
    "        text_size = cv2.getTextSize(class_label, cv2.FONT_HERSHEY_SIMPLEX, 1.5, 2)[0]\n",
    "        cv2.rectangle(image, (xmin, ymin - text_size[1] - 5),\n",
    "                             (xmin + text_size[0], ymin - 1), color, -1)\n",
    "\n",
    "        # Add text\n",
    "        cv2.putText(image, class_label, (xmin, ymin - 5), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 2)\n",
    "\n",
    "    # Convert BGR image to RGB (Matplotlib expects RGB)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Plot the image with annotations\n",
    "    plt.figure(figsize=(18, 10))\n",
    "    plt.imshow(image_rgb)\n",
    "    plt.axis('off')\n",
    "    plt.title('Annotations')\n",
    "    plt.text(10, image_rgb.shape[0] + 100, f'Image: {image_name}',\n",
    "             color='black', fontsize=11, ha='left')\n",
    "    plt.show()\n",
    "\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "_kHrWBvCtN-7",
    "outputId": "6e1c8f61-249e-4ad4-e7a4-f9ef19f7aa8b"
   },
   "outputs": [],
   "source": [
    "image_name = '04_short_03.jpg'\n",
    "visualize_annotations(image_name, images_dir, annot_df, is_subfolder=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FP4z90JkrirL"
   },
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ox9vWEkQdC5z"
   },
   "outputs": [],
   "source": [
    "def resize_images(input_dir, output_dir, target_size=(640, 640)):\n",
    "    # Create the output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Traverse through the subfolders in the input folder\n",
    "    for root, _, files in os.walk(input_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is an image\n",
    "            if file.lower().endswith(('.jpg')):\n",
    "                # Read the image\n",
    "                image_path = os.path.join(root, file)\n",
    "                image = cv2.imread(image_path)\n",
    "\n",
    "                # Resize the image\n",
    "                resized_image = cv2.resize(image, target_size)\n",
    "\n",
    "                # Save the resized image to the output folder\n",
    "                output_path = os.path.join(output_dir, file)\n",
    "                cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "resized_img_dir = os.path.join(dataset_dir, 'images_resized')\n",
    "resize_images(images_dir, resized_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "3BOM8HFBh5vC",
    "outputId": "2eec901f-b900-4d06-e0fe-ef3e3683ad19"
   },
   "outputs": [],
   "source": [
    "def resize_annotations(annot_df, target_size=(640, 640)):\n",
    "    all_data = []\n",
    "\n",
    "    # Iterate through the annotation DataFrame\n",
    "    for index, row in annot_df.iterrows():\n",
    "\n",
    "        # Resize the bounding box coordinates\n",
    "        width_ratio = target_size[0] / row['width']\n",
    "        height_ratio = target_size[1] / row['height']\n",
    "\n",
    "        resized_xmin = int(row['xmin'] * width_ratio)\n",
    "        resized_ymin = int(row['ymin'] * height_ratio)\n",
    "        resized_xmax = int(row['xmax'] * width_ratio)\n",
    "        resized_ymax = int(row['ymax'] * height_ratio)\n",
    "\n",
    "        # Update the all data list with resized annotations\n",
    "        all_data.append({\n",
    "            'filename': row['filename'],\n",
    "            'width': target_size[0],\n",
    "            'height': target_size[1],\n",
    "            'class': row['class'],\n",
    "            'xmin': resized_xmin,\n",
    "            'ymin': resized_ymin,\n",
    "            'xmax': resized_xmax,\n",
    "            'ymax': resized_ymax\n",
    "        })\n",
    "\n",
    "    annot_df_resized = pd.DataFrame(all_data)\n",
    "    return annot_df_resized\n",
    "\n",
    "annot_df_resized = resize_annotations(annot_df)\n",
    "annot_df_resized.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5BiCIHYpCX0b"
   },
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s73xb9aafX6Q"
   },
   "outputs": [],
   "source": [
    "# Create the output directory\n",
    "output_dir = os.path.join(dataset_dir, 'output')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "orcXUURcCb53"
   },
   "outputs": [],
   "source": [
    "# Convert annotation DataFrame into YOLO labels\n",
    "# YOLO format: <class_index> <x_center> <y_center> <width> <height>\n",
    "def convert_to_yolo_labels(annotation_df, classes, target_size=(640, 640)):\n",
    "    yolo_labels = []\n",
    "\n",
    "    for _, annot in annotation_df.iterrows():\n",
    "        filename = annot['filename']\n",
    "        width, height = annot['width'], annot['height']\n",
    "        class_name = annot['class']\n",
    "        xmin, ymin, xmax, ymax = annot['xmin'], annot['ymin'], annot['xmax'], annot['ymax']\n",
    "\n",
    "        # Convert bounding box coordinates to YOLO format\n",
    "        x_center = (xmin + xmax) / (2 * width)\n",
    "        y_center = (ymin + ymax) / (2 * height)\n",
    "        bbox_width = (xmax - xmin) / width\n",
    "        bbox_height = (ymax - ymin) / height\n",
    "\n",
    "        class_index = classes.index(class_name)\n",
    "\n",
    "        # Append to YOLO labels list\n",
    "        yolo_labels.append((filename, class_index, x_center, y_center, bbox_width, bbox_height))\n",
    "\n",
    "    return yolo_labels\n",
    "\n",
    "\n",
    "classes = ['missing_hole', 'mouse_bite', 'open_circuit',\n",
    "           'short', 'spur', 'spurious_copper']\n",
    "yolo_labels = convert_to_yolo_labels(annot_df_resized, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7KFU_EsGHRZ"
   },
   "outputs": [],
   "source": [
    "def split_images_and_labels(images_dir, labels, output_dir, train_split=0.95, val_split=0.05):\n",
    "    # os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images/train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images/val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'images/test'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/train'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/val'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels/test'), exist_ok=True)\n",
    "\n",
    "    # Group labels by image filename\n",
    "    image_labels = {}\n",
    "    for label in labels:\n",
    "        filename, class_index, x_center, y_center, bbox_width, bbox_height = label\n",
    "        if filename not in image_labels:\n",
    "            image_labels[filename] = []\n",
    "        image_labels[filename].append(label)\n",
    "\n",
    "    # Shuffle the image filenames\n",
    "    image_filenames = list(image_labels.keys())\n",
    "    random.shuffle(image_filenames)\n",
    "\n",
    "    # Split the dataset\n",
    "    num_images = len(image_filenames)\n",
    "    num_train = int(num_images * train_split)\n",
    "    num_val = int(num_images * val_split)\n",
    "\n",
    "    train_filenames = image_filenames[:num_train]\n",
    "    val_filenames = image_filenames[num_train:num_train + num_val]\n",
    "    test_filenames = image_filenames[num_train + num_val:]\n",
    "\n",
    "    # Write train, val, test images and labels\n",
    "    for dataset, filenames in [('train', train_filenames), ('val', val_filenames), ('test', test_filenames)]:\n",
    "        for filename in filenames:\n",
    "            labels = image_labels[filename]\n",
    "            with open(os.path.join(output_dir, f'labels/{dataset}/{os.path.splitext(filename)[0]}.txt'), 'a') as label_file:\n",
    "                for label in labels:\n",
    "                    _, class_index, x_center, y_center, bbox_width, bbox_height = label\n",
    "                    label_file.write(f\"{class_index} {x_center} {y_center} {bbox_width} {bbox_height}\\n\")\n",
    "            # Copy images to corresponding folders\n",
    "            shutil.copy(os.path.join(images_dir, filename), os.path.join(output_dir, f'images/{dataset}/{filename}'))\n",
    "\n",
    "split_images_and_labels(resized_img_dir, yolo_labels, output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FQvyo42TWZHQ"
   },
   "source": [
    "# K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mr8v9IWIWYjE"
   },
   "outputs": [],
   "source": [
    "dataset_path = Path(output_dir)\n",
    "labels = sorted(dataset_path.rglob(\"*labels/train/*.txt\")) # all data in 'labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxguULP3X3Bf",
    "outputId": "2ea13c95-26a8-49c3-839c-56d391b3b7cf"
   },
   "outputs": [],
   "source": [
    "cls_idx = list(range(len(classes)))\n",
    "print(list(zip(classes, cls_idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUCCm7K5X-bU"
   },
   "outputs": [],
   "source": [
    "indx = [l.stem for l in labels] # uses base filename as ID (no extension)\n",
    "labels_df = pd.DataFrame([], columns=cls_idx, index=indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TNMwnGbeYEbP",
    "outputId": "88ce498c-08c0-46db-baa1-329e0e463277"
   },
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    lbl_counter = Counter()\n",
    "\n",
    "    with open(label,'r') as lf:\n",
    "        lines = lf.readlines()\n",
    "\n",
    "    for l in lines:\n",
    "        # classes for YOLO label uses integer at first position of each line\n",
    "        lbl_counter[int(l.split(' ')[0])] += 1\n",
    "\n",
    "    labels_df.loc[label.stem] = lbl_counter\n",
    "\n",
    "labels_df = labels_df.fillna(0.0) # replace `nan` values with `0.0`\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp4GxrGxYJET"
   },
   "outputs": [],
   "source": [
    "ksplit = 3\n",
    "kf = KFold(n_splits=ksplit, shuffle=True, random_state=20)   # setting random_state for repeatable results\n",
    "\n",
    "kfolds = list(kf.split(labels_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pg4gW0QSYWVQ"
   },
   "outputs": [],
   "source": [
    "folds = [f'split_{n}' for n in range(1, ksplit + 1)]\n",
    "folds_df = pd.DataFrame(index=indx, columns=folds)\n",
    "\n",
    "for idx, (train, val) in enumerate(kfolds, start=1):\n",
    "    folds_df[f'split_{idx}'].loc[labels_df.iloc[train].index] = 'train'\n",
    "    folds_df[f'split_{idx}'].loc[labels_df.iloc[val].index] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "eyAgw0nnYX0s",
    "outputId": "d92ba636-fcf6-45bc-d003-56be3b0d34dc"
   },
   "outputs": [],
   "source": [
    "fold_lbl_distrb = pd.DataFrame(index=folds, columns=cls_idx)\n",
    "\n",
    "for n, (train_indices, val_indices) in enumerate(kfolds, start=1):\n",
    "    train_totals = labels_df.iloc[train_indices].sum()\n",
    "    val_totals = labels_df.iloc[val_indices].sum()\n",
    "\n",
    "    # To avoid division by zero, we add a small value (1E-7) to the denominator\n",
    "    ratio = val_totals / (train_totals + 1E-7)\n",
    "    fold_lbl_distrb.loc[f'split_{n}'] = ratio\n",
    "\n",
    "fold_lbl_distrb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bsuzSzBkYezu"
   },
   "outputs": [],
   "source": [
    "# Initialize a list to store image file paths\n",
    "images = sorted(dataset_path.rglob(\"*images/train/*.jpg\"))\n",
    "\n",
    "# Create the necessary directories and dataset YAML files (unchanged)\n",
    "save_path = Path(dataset_path / f'{ksplit}fold_crossval')\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "ds_yamls = []\n",
    "\n",
    "for split in folds_df.columns:\n",
    "    # Create directories\n",
    "    split_dir = save_path / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'train' / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'train' / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'val' / 'images').mkdir(parents=True, exist_ok=True)\n",
    "    (split_dir / 'val' / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create dataset YAML files\n",
    "    dataset_yaml = split_dir / f'{split}_dataset.yaml'\n",
    "    ds_yamls.append(dataset_yaml)\n",
    "\n",
    "    with open(dataset_yaml, 'w') as ds_y:\n",
    "        yaml.safe_dump({\n",
    "            'path': split_dir.as_posix(),\n",
    "            'train': 'train',\n",
    "            'val': 'val',\n",
    "            'names': classes\n",
    "        }, ds_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMka5WLoYzE-"
   },
   "outputs": [],
   "source": [
    "for image, label in zip(images, labels):\n",
    "    for split, k_split in folds_df.loc[image.stem].items():\n",
    "        # Destination directory\n",
    "        img_to_path = save_path / split / k_split / 'images'\n",
    "        lbl_to_path = save_path / split / k_split / 'labels'\n",
    "\n",
    "        # Copy image and label files to new directory\n",
    "        shutil.copy(image, img_to_path / image.name)\n",
    "        shutil.copy(label, lbl_to_path / label.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cxBU0VBY_ub"
   },
   "outputs": [],
   "source": [
    "folds_df.to_csv(save_path / \"kfold_datasplit.csv\")\n",
    "fold_lbl_distrb.to_csv(save_path / \"kfold_label_distribution.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qVtG7KOwb4uB"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tErueJdsb3uQ",
    "outputId": "c58a0331-f2a6-479b-8f18-7fe21870873f"
   },
   "outputs": [],
   "source": [
    "model = YOLO('yolov8n.pt')   # nano version only\n",
    "\n",
    "batch = 2                    # keep extremely small\n",
    "imgsz = 416                  # smaller input\n",
    "epochs = 10                  # shorter run for testing\n",
    "mixup = 0.0\n",
    "save_period = 5\n",
    "verbose = True\n",
    "project = 'pcb_ultra_light'\n",
    "results={}\n",
    "\n",
    "for k in range(ksplit):\n",
    "    dataset_yaml = ds_yamls[k]\n",
    "    model.train(\n",
    "        data=dataset_yaml,\n",
    "        epochs=epochs,\n",
    "        batch=batch,\n",
    "        imgsz=imgsz,\n",
    "        lr0=0.001,\n",
    "        lrf=0.0001,\n",
    "        save_period=save_period,\n",
    "        verbose=verbose,\n",
    "        project=project,\n",
    "        device=0,\n",
    "        workers=1,\n",
    "        cache=False,\n",
    "        amp=False   # disable mixed precision (saves VRAM on small GPUs)\n",
    "    )\n",
    "    results[k] = model.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMHeNByV8JKv"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DUzoujU_L2WI",
    "outputId": "f1feb7ba-7a83-4d69-8a60-619ce57747c6"
   },
   "outputs": [],
   "source": [
    "import torch, gc, os\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Use the nano model instead of small (s)\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Light configuration for 4 GB GPU\n",
    "batch = 2                # ↓ 16 → 2\n",
    "imgsz = 416              # ↓ 640 → 416\n",
    "epochs = 10              # ↓ 180 → 80 (you can increase later)\n",
    "mixup = 0.0              # Disable heavy augmentations\n",
    "save_period = 5          # Saves every 5 epochs to reduce disk writes\n",
    "verbose = True\n",
    "project = 'pcb_light'\n",
    "\n",
    "# Your dataset YAML\n",
    "all_data_yaml = f\"\"\"\n",
    "path: {output_dir}\n",
    "train: images/train\n",
    "val: images/val\n",
    "\n",
    "names:\n",
    "    0: missing_hole\n",
    "    1: mouse_bite\n",
    "    2: open_circuit\n",
    "    3: short\n",
    "    4: spur\n",
    "    5: spurious_copper\n",
    "\"\"\"\n",
    "\n",
    "data_path = os.path.join(root_dir, 'data.yaml')\n",
    "with open(data_path, 'w') as f:\n",
    "    f.write(all_data_yaml)\n",
    "\n",
    "# Train\n",
    "result = model.train(\n",
    "    data=data_path,\n",
    "    epochs=epochs,\n",
    "    batch=batch,\n",
    "    imgsz=imgsz,\n",
    "    lr0=0.001,\n",
    "    lrf=0.0001,\n",
    "    save_period=save_period,\n",
    "    verbose=verbose,\n",
    "    project=project,\n",
    "    device=0,\n",
    "    workers=1,\n",
    "    cache=False,\n",
    "    amp=False       # disables mixed precision → fewer VRAM spikes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "XsprK7peOHFE",
    "outputId": "c150eb69-901b-499a-b974-6bb97da2981a"
   },
   "outputs": [],
   "source": [
    "results_dir = '//home/arm/Downloads/PCB/pcb_light/train3'\n",
    "dest_results_dir = os.path.join(root_dir, 'results')\n",
    "\n",
    "shutil.copytree(results_dir, dest_results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "wzL0ck_4mIER",
    "outputId": "6a52923b-c355-44a7-b101-f89967f85acb"
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv(os.path.join(dest_results_dir, 'results.csv'))\n",
    "results_df.columns = results_df.columns.str.strip()\n",
    "results_df = results_df.apply(pd.to_numeric, errors='coerce').dropna()\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "-HaskkdzC2g1",
    "outputId": "ad0783f5-da68-4404-c5d7-5b081100e9d1"
   },
   "outputs": [],
   "source": [
    "epochs = results_df['epoch']\n",
    "train_box_loss = results_df['train/box_loss']\n",
    "val_box_loss = results_df['val/box_loss']\n",
    "train_cls_loss = results_df['train/cls_loss']\n",
    "val_cls_loss = results_df['val/cls_loss']\n",
    "train_dfl_loss = results_df['train/dfl_loss']\n",
    "val_dfl_loss = results_df['val/dfl_loss']\n",
    "\n",
    "# Create a figure with three subplots\n",
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot box loss\n",
    "axs[0].plot(epochs, train_box_loss, label='Train Box Loss', color='blue')\n",
    "axs[0].plot(epochs, val_box_loss, label='Validation Box Loss', color='orange')\n",
    "axs[0].set_title('Box Loss')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Plot cls loss\n",
    "axs[1].plot(epochs, train_cls_loss, label='Train Cls Loss', color='blue')\n",
    "axs[1].plot(epochs, val_cls_loss, label='Validation Cls Loss', color='orange')\n",
    "axs[1].set_title('Class Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# Plot dfl loss\n",
    "axs[2].plot(epochs, train_dfl_loss, label='Train Dfl Loss', color='blue')\n",
    "axs[2].plot(epochs, val_dfl_loss, label='Validation Dfl Loss', color='orange')\n",
    "axs[2].set_title('Distribution Focal Loss')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].set_ylabel('Loss')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0dZZD_LqbbF"
   },
   "source": [
    "# Predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IJAimwD7qbLQ",
    "outputId": "c2b43f8a-af11-4d26-8e0f-bdbd2a5e66c5"
   },
   "outputs": [],
   "source": [
    "best_model_path = os.path.join(dest_results_dir, 'weights/best.pt')\n",
    "model = YOLO(best_model_path)\n",
    "\n",
    "test_data_dir = os.path.join(output_dir, 'images/val')\n",
    "metrics = model(source=test_data_dir, imgsz=640, conf=0.25, save=True, save_txt=True, save_conf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ceuNG333jmy0",
    "outputId": "394e9a7a-8eb5-4b78-83f6-34b5c3b4ad76"
   },
   "outputs": [],
   "source": [
    "predict_dir = '/home/arm/Downloads/PCB/runs/detect/predict2/labels'\n",
    "dest_predict_dir = os.path.join(root_dir, 'results/predict2')\n",
    "\n",
    "shutil.copytree(predict_dir, dest_predict_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uvbFG1PXt7dt"
   },
   "outputs": [],
   "source": [
    "def yolo_to_original_annot(image_name, yolo_labels, annot_df, classes):\n",
    "    original_annot = []\n",
    "\n",
    "    for yolo_label in yolo_labels:\n",
    "        # Extract original width and height from annotation DataFrame\n",
    "        original_size = annot_df.loc[annot_df['filename'] == image_name, ['width', 'height']].iloc[0]\n",
    "        original_width, original_height = original_size['width'], original_size['height']\n",
    "\n",
    "        # Extract YOLO label components\n",
    "        class_index, x_center, y_center, bbox_width, bbox_height, confidence = yolo_label\n",
    "\n",
    "        # Scale bounding box coordinates and dimensions to original size\n",
    "        original_x_center = x_center * original_width\n",
    "        original_y_center = y_center * original_height\n",
    "        original_bbox_width = bbox_width * original_width\n",
    "        original_bbox_height = bbox_height * original_height\n",
    "\n",
    "        # Calculate original bounding box coordinates\n",
    "        original_x_min = original_x_center - original_bbox_width / 2\n",
    "        original_y_min = original_y_center - original_bbox_height / 2\n",
    "        original_x_max = original_x_center + original_bbox_width / 2\n",
    "        original_y_max = original_y_center + original_bbox_height / 2\n",
    "\n",
    "        # Append original annotation to list\n",
    "        original_annot.append({\n",
    "            'filename': image_name,\n",
    "            'width': int(original_width),\n",
    "            'height': int(original_height),\n",
    "            'class': classes[int(class_index)],\n",
    "            'xmin': int(original_x_min),\n",
    "            'ymin': int(original_y_min),\n",
    "            'xmax': int(original_x_max),\n",
    "            'ymax': int(original_y_max),\n",
    "            'confidence': confidence\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(original_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9HGCGx-YAvJ",
    "outputId": "0cdb1350-2485-40f8-9e9f-d1c95a801eff"
   },
   "outputs": [],
   "source": [
    "def read_yolo_labels_from_file(file_path):\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            values = line.strip().split()\n",
    "            values = [float(value) for value in values]\n",
    "            labels.append(values)\n",
    "    return labels\n",
    "\n",
    "file_path = os.path.join(dest_predict_dir, '12_spurious_copper_10.txt')\n",
    "yolo_labels = read_yolo_labels_from_file(file_path)\n",
    "yolo_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "4f0S8AGpZbyb",
    "outputId": "7010b266-0f01-4ee8-b36b-200e6752f4d8"
   },
   "outputs": [],
   "source": [
    "pred_annot_df = yolo_to_original_annot('12_spurious_copper_10.jpg', yolo_labels, annot_df, classes)\n",
    "pred_annot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "qBNL6gdVj14w",
    "outputId": "eac0ac95-bacd-465f-e737-ee4877ce7b9d"
   },
   "outputs": [],
   "source": [
    "visualize_annotations('12_spurious_copper_10.jpg', images_dir, pred_annot_df, is_subfolder=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 864
    },
    "id": "zNDoWxRvkXdp",
    "outputId": "0dcb7c97-56bd-4be6-d293-74f7ce947bed"
   },
   "outputs": [],
   "source": [
    "visualize_annotations('12_spurious_copper_10.jpg', images_dir, annot_df, is_subfolder=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270
    },
    "id": "r5C3i7e1FHww",
    "outputId": "984c8610-f7bc-4d80-c133-fcab3d1d6fc2"
   },
   "outputs": [],
   "source": [
    "model.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlZkiiYVFAA0"
   },
   "outputs": [],
   "source": [
    "custom_img_dir = os.path.join(root_dir, 'custom_images')\n",
    "resized_custom_img_dir = os.path.join(custom_img_dir, 'resized')\n",
    "resize_images(custom_img_dir, resized_custom_img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpY3xBk85YTK",
    "outputId": "5fcd61a1-1e64-43f0-e9ce-1ed7c5645c2f"
   },
   "outputs": [],
   "source": [
    "model = YOLO(best_model_path)\n",
    "\n",
    "image_path = os.path.join(resized_custom_img_dir, '01.jpg')\n",
    "result_custom = model(image_path, imgsz=640, conf=0.25, save=True, save_txt=True, save_conf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "EZdTwTBhF2CD",
    "outputId": "400129aa-3527-4b7b-fc18-19a9023155e7"
   },
   "outputs": [],
   "source": [
    "predict_dir = '/home/arm/Downloads/PCB/runs/detect/predict2/labels'\n",
    "dest_custom_predict_dir = os.path.join(custom_img_dir, 'results/predict2')\n",
    "\n",
    "shutil.copytree(predict_dir, dest_custom_predict_dir)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (ml_class)",
   "language": "python",
   "name": "ml_class"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
